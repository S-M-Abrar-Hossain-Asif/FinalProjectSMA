{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a23c0fc",
   "metadata": {},
   "source": [
    "Sentiment Reddit by Abrar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db97936d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk \n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f60e6ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dtypes = {'Id':'category','type':'category','subreddit':'category','score':'float64','title':'category','reviews':'category','author':'category'}\n",
    "ds= pd.read_excel(\"reddit_FINAL_v12.xlsx\", sheet_name=\"Sheet1\", engine='openpyxl', dtype=dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd7f7344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>type</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>reviews</th>\n",
       "      <th>author</th>\n",
       "      <th>date_published</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>post</td>\n",
       "      <td>iphone</td>\n",
       "      <td>Iphone 14 leather cases like andar brand but i...</td>\n",
       "      <td>Are there any? I don't wanna wait a month to r...</td>\n",
       "      <td>New-Analysis8054</td>\n",
       "      <td>2023-04-29 07:22:04</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>comment</td>\n",
       "      <td>iphone</td>\n",
       "      <td>Iphone 14 leather cases like andar brand but i...</td>\n",
       "      <td>Mujjo and Solo Pelle both make great leather c...</td>\n",
       "      <td>ShortOnCoffee</td>\n",
       "      <td>2023-04-29 07:52:29</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>comment</td>\n",
       "      <td>iphone</td>\n",
       "      <td>Iphone 14 leather cases like andar brand but i...</td>\n",
       "      <td>I use Mujjo. Another brand is Decoded.</td>\n",
       "      <td>uwGrootsheid</td>\n",
       "      <td>2023-04-29 10:29:29</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>post</td>\n",
       "      <td>iphone</td>\n",
       "      <td>Why is my screen time incorrect?</td>\n",
       "      <td>Barely used my phone today but it shows 3 hours.</td>\n",
       "      <td>tyler_ness</td>\n",
       "      <td>2023-04-28 21:07:35</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>comment</td>\n",
       "      <td>iphone</td>\n",
       "      <td>Why is my screen time incorrect?</td>\n",
       "      <td>It shows your usage from your other devices li...</td>\n",
       "      <td>lovekorra</td>\n",
       "      <td>2023-04-29 05:45:35</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Id     type subreddit                                              title  \\\n",
       "0  1     post    iphone  Iphone 14 leather cases like andar brand but i...   \n",
       "1  2  comment    iphone  Iphone 14 leather cases like andar brand but i...   \n",
       "2  3  comment    iphone  Iphone 14 leather cases like andar brand but i...   \n",
       "3  4     post    iphone                   Why is my screen time incorrect?   \n",
       "4  5  comment    iphone                   Why is my screen time incorrect?   \n",
       "\n",
       "                                             reviews            author  \\\n",
       "0  Are there any? I don't wanna wait a month to r...  New-Analysis8054   \n",
       "1  Mujjo and Solo Pelle both make great leather c...     ShortOnCoffee   \n",
       "2             I use Mujjo. Another brand is Decoded.      uwGrootsheid   \n",
       "3   Barely used my phone today but it shows 3 hours.        tyler_ness   \n",
       "4  It shows your usage from your other devices li...         lovekorra   \n",
       "\n",
       "       date_published  score  \n",
       "0 2023-04-29 07:22:04    1.0  \n",
       "1 2023-04-29 07:52:29    1.0  \n",
       "2 2023-04-29 10:29:29    1.0  \n",
       "3 2023-04-28 21:07:35    1.0  \n",
       "4 2023-04-29 05:45:35    1.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check first rows\n",
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51b69152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text preprocessing\n",
    "def textPreProcess(rawText, removeHTML=True, charsToRemove = r'\\?|\\.|\\!|\\;|\\.|\\\"|\\,|\\(|\\)|\\&|\\:|\\-', removeNumbers=True, removeLineBreaks=False, specialCharsToRemove = r'[^\\x00-\\xfd]', convertToLower=True, removeConsecutiveSpaces=True):\n",
    "    if type(rawText) != str:\n",
    "        return rawText\n",
    "    procText = rawText\n",
    "        \n",
    "    # Remove HTML\n",
    "    if removeHTML:\n",
    "        procText = BeautifulSoup(procText,'html.parser').get_text()\n",
    "\n",
    "    # Remove punctuation and other special characters\n",
    "    if len(charsToRemove)>0:\n",
    "        procText = re.sub(charsToRemove,' ',procText)\n",
    "\n",
    "    # Remove numbers\n",
    "    if removeNumbers:\n",
    "        procText = re.sub(r'\\d+',' ',procText)\n",
    "\n",
    "    # Remove line breaks\n",
    "    if removeLineBreaks:\n",
    "        procText = procText.replace('\\n',' ').replace('\\r', '')\n",
    "\n",
    "    # Remove special characters\n",
    "    if len(specialCharsToRemove)>0:\n",
    "        procText = re.sub(specialCharsToRemove,' ',procText)\n",
    "\n",
    "    # Normalize to lower case\n",
    "    if convertToLower:\n",
    "        procText = procText.lower() \n",
    "\n",
    "    # Replace multiple consecutive spaces with just one space\n",
    "    if removeConsecutiveSpaces:\n",
    "        procText = re.sub(' +', ' ', procText)\n",
    "\n",
    "    return procText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06840f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize words\n",
    "def tokenize_words(words):\n",
    "    if (type(words) != str) or (word_tokenize(words) == ''):\n",
    "        return np.nan\n",
    "    else:\n",
    "        return word_tokenize(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8e4f165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create text from words\n",
    "def recreateText(words):\n",
    "    if type(words) == list:\n",
    "        temp_str = (' ').join(words)\n",
    "        return temp_str\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec4e87cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to break texts into sentences\n",
    "def tokenize_sentences(texts):\n",
    "    s_token = sent_tokenize(texts)\n",
    "    return s_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a68dae95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove stop words\n",
    "def removeStopWords(t, stop_words):\n",
    "    if type(t) == list:\n",
    "        return [w for w in t if not w in stop_words]\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e0ceec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6040d88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_sentences(text):\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    return \". \".join(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ea95f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because a review can express multiple opinions, let's analyze opinions by sentence\n",
    "\n",
    "# Break reviews' into a list of lists sentences\n",
    "listOfSentences = ds.reviews.apply(tokenize_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c52778d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asifa\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:431: MarkupResemblesLocatorWarning: \"https://iaohi.com/products/aohi-magcube-65w-pd-fast-charger\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "C:\\Users\\asifa\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:431: MarkupResemblesLocatorWarning: \"https://preview.redd.it/yqvdvjj1r8wa1.jpeg?width=640&format=pjpg&auto=webp&v=enabled&s=10f145dc1c4c69eb3b08c6716b4ab2676564fe19\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Create a dataframe with only the description\n",
    "processedReviews = pd.DataFrame(data=ds.reviews.apply(textPreProcess,charsToRemove ='', removeLineBreaks=False, removeNumbers=False).values, index=ds.index, columns=['PreProcessedText'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e76fb00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Are there any? I don't wanna wait a month to receive it, i live in italy if that matters\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check first review\n",
    "ds.reviews[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d64dd092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Are there any?. I don't wanna wait a month to receive it, i live in italy if that matters\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listOfSentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d87eb544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split sentences and count the number of sentences per review\n",
    "reviews_str = ds['reviews'].astype(str)\n",
    "sentences = pd.DataFrame(reviews_str.str.split('.').tolist(), index=ds['Id']).stack()\n",
    "sentencesPerReview = [len(elem) for elem in reviews_str.str.split('.')]\n",
    " \n",
    "# Create a new DataFrame with the sentences and their respective IDs\n",
    "sentences.name = 'sentence'\n",
    "sentences.index.names = ['Id', 'sentence_no']\n",
    "sentences = sentences.reset_index().set_index('Id')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d685c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "def text_preprocess(text):\n",
    "    \"\"\"\n",
    "    Preprocess text data by converting to lowercase, removing punctuation and digits, and removing extra whitespaces.\n",
    "    \"\"\"\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Remove digits\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    # Remove extra whitespaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "# Preprocess text \n",
    "sentences['PreProcessedText'] = sentences['sentence'].apply(text_preprocess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e921f8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get words\n",
    "sentences['Words'] =  sentences['PreProcessedText'].apply(tokenize_words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e87f7a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\asifa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "53462829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "sentences['WordsCleaned'] = sentences['Words'].apply(removeStopWords,stop_words=stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "17bcf75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate sentence without stopwords\n",
    "sentences['ProcessedText'] = sentences['WordsCleaned'].apply(recreateText)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c3519244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sentiment analysis object\n",
    "analyser = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8f446087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dont wan na wait month receive live italy matters {'neg': 0.0, 'neu': 0.879, 'pos': 0.121, 'compound': 0.0258}\n"
     ]
    }
   ],
   "source": [
    "# To test, let's evaluate first sentence of first review\n",
    "# Scales:\n",
    "#   compound: -1:most extreme negative, 1:most extreme positive\n",
    "#     positive: compound >=0.05\n",
    "#     neutral: -0.05<compound<0.05\n",
    "#     negative: compound <= -0.05\n",
    "#   pos, neu, neg: proportion of text that are positive, neutral or negative\n",
    "score = analyser.polarity_scores(sentences['ProcessedText'][0])\n",
    "print(sentences['ProcessedText'][0],score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6e80c4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process sentiment for all sentences\n",
    "all_scores = []\n",
    "for t in (sentences['ProcessedText'][:]):\n",
    "  score = analyser.polarity_scores(t)\n",
    "  all_scores.append(score)\n",
    "sentences['Sentiment'] = [c['compound'] for c in all_scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1970fffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute review's sentiment as the mean sentiment from its sentences\n",
    "meanByReview = sentences.groupby('Id')['Sentiment'].mean()\n",
    "\n",
    "# Consider sentences with no result as neutral (0)\n",
    "meanByReview = meanByReview.fillna(0)\n",
    "\n",
    "# Add column Sentiment to reviews Dataframe\n",
    "ds['Sentiment'] = meanByReview[ds['Id']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "63013fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = pd.IntervalIndex.from_tuples([(-1.1, -0.05), (-0.05, 0.05), (0.05, 1)], closed='right')\n",
    "x = pd.cut(ds['Sentiment'].to_list(), bins)\n",
    "x = x.set_categories(['Negative','Neutral','Positive'])\n",
    "ds['Polarity'] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "804bd08b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Apple 20w charger or Anker 20w Nano</th>\n",
       "      <td>0.129564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Apple care</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Applecare+, is it worth it?</th>\n",
       "      <td>0.034008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BEST CASE FOR IPHONE 14</th>\n",
       "      <td>0.206869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Black Bar at Top</th>\n",
       "      <td>0.133020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iPhone not turning on</th>\n",
       "      <td>0.203391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>my iphone 14 camera automatically edits my photos, i cant figure out how to stop it</th>\n",
       "      <td>0.044548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phone getting really hot</th>\n",
       "      <td>0.002800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weird group chat text issue</th>\n",
       "      <td>-0.000131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>what tf is this and why is it happening??!! (iphone 14)</th>\n",
       "      <td>0.037205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Sentiment\n",
       "title                                                        \n",
       "Apple 20w charger or Anker 20w Nano                  0.129564\n",
       "Apple care                                           0.000000\n",
       "Applecare+, is it worth it?                          0.034008\n",
       "BEST CASE FOR IPHONE 14                              0.206869\n",
       "Black Bar at Top                                     0.133020\n",
       "...                                                       ...\n",
       "iPhone not turning on                                0.203391\n",
       "my iphone 14 camera automatically edits my phot...   0.044548\n",
       "phone getting really hot                             0.002800\n",
       "weird group chat text issue                         -0.000131\n",
       "what tf is this and why is it happening??!! (ip...   0.037205\n",
       "\n",
       "[74 rows x 1 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analysis examples:\n",
    "# By title\n",
    "ex1 = ds.groupby('title')['Sentiment'].mean().to_frame()\n",
    "ex1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "30d1b57d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>score</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>comment</td>\n",
       "      <td>-222.0</td>\n",
       "      <td>0.0258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>comment</td>\n",
       "      <td>-82.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>comment</td>\n",
       "      <td>-32.0</td>\n",
       "      <td>-0.2083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>comment</td>\n",
       "      <td>-31.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>comment</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>-0.5106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>post</td>\n",
       "      <td>260.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>post</td>\n",
       "      <td>283.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>post</td>\n",
       "      <td>310.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>post</td>\n",
       "      <td>375.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>post</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        type   score  Sentiment\n",
       "0    comment  -222.0     0.0258\n",
       "1    comment   -82.0     0.0000\n",
       "2    comment   -32.0    -0.2083\n",
       "3    comment   -31.0     0.0000\n",
       "4    comment   -25.0    -0.5106\n",
       "..       ...     ...        ...\n",
       "137     post   260.0        NaN\n",
       "138     post   283.0        NaN\n",
       "139     post   310.0        NaN\n",
       "140     post   375.0     0.0000\n",
       "141     post  1023.0     0.0000\n",
       "\n",
       "[142 rows x 3 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analysis examples:\n",
    "#By comment type and score\n",
    "ex2 = ds[['type','score','Sentiment']].groupby(['type','score'], as_index=False).mean()\n",
    "ex2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635d4af5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ce74eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
